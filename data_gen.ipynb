{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342dfd3b-48e3-4008-8458-da4020f95bcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485f5d5-3281-495f-8112-29c4c5d8989e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Task Duration Config\n",
    "For each task type that could be generated we need an average duration and a maximum duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load task duration dataframe\n",
    "#task_duration_df = pd.read_csv('task_duration_config.csv')\n",
    "#task_duration_df.set_index('Task', inplace=True)\n",
    "\n",
    "data = [['New Client Onboarding Request', 0.5,1.5], \n",
    "        ['Review Documents', 0.25,  2.5], \n",
    "        ['Automated Scoreboarding', 0.1, 0.15],\n",
    "        ['Manual Scoreboarding', 1.0, 3.0],\n",
    "        ['Update Backend Systems', 0.25, 0.5],\n",
    "        ['Notification Review Request Completed', 0.1, 0.15]\n",
    "       ]\n",
    "\n",
    "task_duration_df = pd.DataFrame(data, columns=['Task', 'Avg', 'Max'])\n",
    "task_duration_df.set_index('Task', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#task_duration_df = pd.read_csv('task_duration_config.csv')\n",
    "#task_duration_df.set_index('Task', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task_duration_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate Process Instances\n",
    "This function manages the creation of process instances for a specific process variant. A process variant is simply the list of tasks in execution order, including any loops. For example ['Wake Up', 'Breakfast', 'Work', 'Dinner' 'Sleep']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "def generate_process_instances(process_variant, qty):\n",
    "\n",
    "    global start_date_time\n",
    "    global instance_counter\n",
    "    task_list = []\n",
    "    for x in range(0, qty):\n",
    "        tasks = build_task_list(instance_counter, process_variant, start_date_time, task_duration_df)\n",
    "        for task in tasks:\n",
    "            task_list.append(task)\n",
    "\n",
    "        # Increment the start time by 24 hour\n",
    "        start_date_time = start_date_time + timedelta(hours=24)\n",
    "        # Increment the process_id\n",
    "        instance_counter = instance_counter +1\n",
    "        \n",
    "    return task_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Task List\n",
    "The build_task_list function creates a list of tasks for a specific instance of a process. The sequence of tasks is defined in the variable called process_variant. Random task durations are calculated using the task_durations_df that contains the task name, the average duration and the max duration.  \n",
    "\n",
    "This code generates a random duration by leveraging the numpy lognormal function that gives a random\n",
    "number drawn from a log normal distribution. Look up a picture of log normal distributions and you'll see \n",
    "why this is useful for generating random durations based on a mean and std deviation.\n",
    "most samples are near the average with a long tail stretching towards infinity.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_task_list(instance_id, process_variant, start_date_time, task_duration_df):\n",
    "    instance_task_list = []\n",
    "    rnd = np.random.default_rng()  # a random number generator\n",
    "\n",
    "    # process_variant is a series\n",
    "    for task_type in process_variant:\n",
    "        # get the avg and max durations from the task_df dataframe using task_type as the key\n",
    "        avg_dur = task_duration_df.loc[task_type, 'Avg']\n",
    "        max_dur = task_duration_df.loc[task_type, 'Max']\n",
    "\n",
    "        sigma = (max_dur - avg_dur) / max_dur  # std dev\n",
    "        log_mean = np.log(avg_dur)  # can't pass the mean duration into lognormal until it has been logged itself \n",
    "        delta = rnd.lognormal(log_mean, sigma)  # get a random sample from a log normal distribution with a std dev\n",
    "\n",
    "        task = [instance_id, task_type, start_date_time]\n",
    "        instance_task_list.append(task)\n",
    "\n",
    "        # increment the start time by the delta so that the next task start after this one\n",
    "        start_date_time = start_date_time + timedelta(hours=delta)\n",
    "\n",
    "    return instance_task_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Â Shift Activity Start Time\n",
    "This function shifts the activity start time for a specific task with a specific attribute set to a specific value. For example, to delay the start time of breakfast by 1hour \"task_list, User, Gerry, Eat Breakfast, 1\"\n",
    "\n",
    "This function will apply the same timeshift to every subsequent task in the proccess instance. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shiftActivityStartTime(tasks, target_attribute, target_value, target_task, timeShift):\n",
    "\n",
    "    # Logic requires we sort by process_id and start_date\n",
    "    tasks = tasks.sort_values(['process_id', 'start_time'])\n",
    "    tasks = tasks.reset_index(drop=True)\n",
    "    process_being_modified = -1\n",
    "\n",
    "    # iterate through the dataframe using the index value\n",
    "    for x in tasks.index:\n",
    "        row = tasks.loc[x]\n",
    "        task_attribute = row[target_attribute]\n",
    "        row_task = row['task']\n",
    "        current_process = row['process_id']\n",
    "\n",
    "\n",
    "        # Have we found the target activity\n",
    "        if row_task == target_task and task_attribute == target_value:\n",
    "            process_being_modified = current_process\n",
    "\n",
    "        # Are we still processing the same process that we were when we found the target activity ?\n",
    "        # If so we are moving all subsequent tasks back by the value of the timeshift parameter\n",
    "        if current_process == process_being_modified:\n",
    "            # shift the time\n",
    "            current_ts = row['start_time']\n",
    "            shifted_ts = current_ts + timedelta(hours=timeShift)\n",
    "            tasks.loc[x, 'start_time'] = shifted_ts\n",
    "\n",
    "    return tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialise Data Generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_date_time = datetime(2017, 11, 28, 18, 00, 00)\n",
    "instance_time_offset = 24\n",
    "instance_counter = 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Happy Path Instances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "qty = 10\n",
    "happy_path = [\"New Client Onboarding Request\", \n",
    "               \"Review Documents\", \n",
    "               \"Automated Scoreboarding\",\n",
    "               \"Update Backend Systems\", \n",
    "               \"Notification Review Request Completed\"]\n",
    "\n",
    "happy_path_task_list = []\n",
    "happy_path_task_list = generate_process_instances(happy_path, qty)\n",
    "happy_path_task_list_df = pd.DataFrame(happy_path_task_list)\n",
    "\n",
    "# Increment the start time by 24 hour\n",
    "start_date_time = start_date_time + timedelta(hours=24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "happy_path_task_list_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Instances Requiring Manual Scoreboarding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "qty = 5\n",
    "manual_path = [\"New Client Onboarding Request\", \n",
    "               \"Review Documents\", \n",
    "               \"Automated Scoreboarding\",\n",
    "               \"Manual Scoreboarding\",\n",
    "               \"Update Backend Systems\", \n",
    "               \"Notification Review Request Completed\"]\n",
    "\n",
    "manual_path_task_list = []\n",
    "manual_path_task_list = generate_process_instances(manual_path, qty)\n",
    "manual_path_task_list_df = pd.DataFrame(manual_path_task_list)\n",
    "\n",
    "# Increment the start time by 24 hour\n",
    "start_date_time = start_date_time + timedelta(hours=24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "manual_path_task_list_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Instance that loop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qty = 1\n",
    "loop_path = [\"New Client Onboarding Request\", \n",
    "               \"Review Documents\", \n",
    "               \"Automated Scoreboarding\",\n",
    "               \"Manual Scoreboarding\",\n",
    "               \"Review Documents\",\n",
    "               \"Update Backend Systems\", \n",
    "               \"Notification Review Request Completed\"]\n",
    "\n",
    "loop_path_task_list = []\n",
    "loop_path_task_list = generate_process_instances(loop_path, qty)\n",
    "loop_path_task_list_df = pd.DataFrame(loop_path_task_list)\n",
    "\n",
    "# Increment the start time by 24 hour\n",
    "start_date_time = start_date_time + timedelta(hours=24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Can only concat two dataframes at a time\n",
    "combined_df = pd.concat([happy_path_task_list_df,manual_path_task_list_df], axis=0)\n",
    "combined_df = pd.concat([combined_df,loop_path_task_list_df], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df.columns = ['process_id', 'task', 'start_time']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Confirm how many processes\n",
    "len(combined_df[\"process_id\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df.head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Task Level Business Data : User"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Add a column for User\n",
    "combined_df[\"user\"] = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def setRandomUser(row):\n",
    "    match row[\"task\"]:\n",
    "        case \"Review Documents\":\n",
    "            return random.choice(['Rod','Jane','Freddy'])\n",
    "        case \"New Client Onboarding Request\":\n",
    "            return random.choice(['Clive','Francis','Nick','Seb','Tom'])\n",
    "        case \"Manual Scoreboarding\":\n",
    "            return random.choice(['Sharon','Susan', 'Sam'])\n",
    "        case \"Update Backend Systems\":\n",
    "            return \"RPA\"\n",
    "        case \"Automated Scoreboarding\":\n",
    "            return \"SYSTEM\"\n",
    "        case \"Notification Review Request Completed\":\n",
    "            return \"SYSTEM\"\n",
    "        case _:\n",
    "            return row[\"user\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df[\"user\"] = combined_df.apply(setRandomUser, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Process Instance Business Data : Industry\n",
    "Industy won't change during the process so all tasks for a given process ID must have the same value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df[\"industry\"] = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "process_id_list = combined_df[\"process_id\"].unique()\n",
    "\n",
    "for process_id in process_id_list:\n",
    "    industry = random.choice(['Federal','Finance','Healthcare','Insurance','Telecom'])\n",
    "    combined_df.loc[combined_df[\"process_id\"].eq(process_id), \"industry\"] = industry\n",
    "    \n",
    "                          \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Process Instance Business Data : Service Charge\n",
    "Service charge will be a random choice based on industry."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df[\"service_charge\"] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getServiceChargeByIndustry(industry):\n",
    "    match industry:\n",
    "        case \"Federal\":\n",
    "            return random.choice([3000, 6000, 8000])\n",
    "        case \"Finance\":\n",
    "            return random.choice([10000, 12000, 20000])\n",
    "        case \"Healthcare\":\n",
    "            return random.choice([15000, 20000, 25000])\n",
    "        case \"Insurance\":\n",
    "            return 45000\n",
    "        case \"Telecom\":\n",
    "            return 49000\n",
    "        case _:\n",
    "            return 64000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_process = -1\n",
    "service_charge = 0\n",
    "\n",
    "process_id_list = combined_df[\"process_id\"].unique()\n",
    "\n",
    "for process_id in process_id_list:\n",
    "        # what industry is set for this process_id\n",
    "        process_instance_tasks = combined_df.loc[combined_df.process_id == process_id].copy()\n",
    "        industry = process_instance_tasks.iloc[0]['industry']\n",
    "        service_charge = getServiceChargeByIndustry(industry)\n",
    "        combined_df.loc[combined_df.process_id == process_id, 'service_charge'] = service_charge\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combined_df.head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# next look at increasing the time taken for automated scoreboarding to start when the industry is federal\n",
    "# do th same for healthcare\n",
    "# rational here is that the documentation requirements are greater\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If user is Rod and activity is `Review Documents` shift the start_time by 1 hour\n",
    "updated_df = shiftActivityStartTime(combined_df, 'user','Rod', 'Review Documents', 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filter = (combined_df['process_id'] == 3)\n",
    "combined_df[filter]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filter = (updated_df['process_id'] == 3)\n",
    "updated_df[filter]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}