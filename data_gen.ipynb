{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342dfd3b-48e3-4008-8458-da4020f95bcd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Utility Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate Process Instances\n",
    "This function manages the creation of process instances for a specific process variant. A process variant is simply the list of tasks in execution order, including any loops. For example ['Wake Up', 'Breakfast', 'Work', 'Dinner' 'Sleep']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_process_instances(process_variant, qty):\n",
    "\n",
    "    global start_date_time\n",
    "    global instance_counter\n",
    "    task_list = []\n",
    "    for x in range(0, qty):\n",
    "        tasks = build_task_list(instance_counter, process_variant, start_date_time, task_duration_df)\n",
    "        for task in tasks:\n",
    "            task_list.append(task)\n",
    "\n",
    "        # Increment the start time by 24 hour\n",
    "        start_date_time = start_date_time + timedelta(hours=24)\n",
    "        # Increment the process_id\n",
    "        instance_counter = instance_counter +1\n",
    "        \n",
    "    return task_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build Task List\n",
    "The build_task_list function creates a list of tasks for a specific instance of a process. The sequence of tasks is defined in the variable called process_variant. Random task durations are calculated using the task_durations_df that contains the task name, the average duration and the max duration.  \n",
    "\n",
    "This code generates a random duration by leveraging the numpy lognormal function that gives a random\n",
    "number drawn from a log normal distribution. Look up a picture of log normal distributions and you'll see \n",
    "why this is useful for generating random durations based on a mean and std deviation.\n",
    "most samples are near the average with a long tail stretching towards infinity.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_task_list(instance_id, process_variant, start_date_time, task_duration_df):\n",
    "    instance_task_list = []\n",
    "    rnd = np.random.default_rng()  # a random number generator\n",
    "\n",
    "    # process_variant is a series\n",
    "    for task_type in process_variant:\n",
    "        # get the avg and max durations from the task_df dataframe using task_type as the key\n",
    "        avg_dur = task_duration_df.loc[task_type, 'Avg']\n",
    "        max_dur = task_duration_df.loc[task_type, 'Max']\n",
    "\n",
    "        sigma = (max_dur - avg_dur) / max_dur  # std dev\n",
    "        log_mean = np.log(avg_dur)  # can't pass the mean duration into lognormal until it has been logged itself \n",
    "        delta = rnd.lognormal(log_mean, sigma)  # get a random sample from a log normal distribution with a std dev\n",
    "        end_time = start_date_time + timedelta(hours=delta)\n",
    "        task = [instance_id, task_type, start_date_time, end_time]\n",
    "        instance_task_list.append(task)\n",
    "\n",
    "        # set the start time of the next tasks to be 5 mins after the end time of this task\n",
    "        start_date_time = end_time + timedelta(minutes=5)\n",
    "\n",
    "    return instance_task_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delay Task Start Time\n",
    "This function shifts the task start time for a specific task with a specific attribute set to a specific value. For example, to delay the start time of breakfast by 1hour \"task_list, User, Gerry, Eat Breakfast, 1\"\n",
    "\n",
    "This function will apply the same delay to every subsequent task of the process instance. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def delayStartTime(tasks, target_attribute, target_value, target_task, timeShift):\n",
    "\n",
    "    # Logic requires we sort by process_id and start_date\n",
    "    tasks = tasks.sort_values(['process_id', 'start_time'])\n",
    "    tasks = tasks.reset_index(drop=True)\n",
    "    process_being_modified = -1\n",
    "\n",
    "    # iterate through the dataframe using the index value\n",
    "    for x in tasks.index:\n",
    "        row = tasks.loc[x]\n",
    "        task_attribute = row[target_attribute]\n",
    "        row_task = row['task']\n",
    "        current_process = row['process_id']\n",
    "\n",
    "\n",
    "        # Have we found the target activity\n",
    "        if row_task == target_task and task_attribute == target_value:\n",
    "            process_being_modified = current_process\n",
    "\n",
    "        # Are we still processing the same process that we were when we found the target activity ?\n",
    "        # If so we are moving all subsequent tasks back by the value of the timeshift parameter,\n",
    "        # this means shifting the start time and the end time\n",
    "        if current_process == process_being_modified:\n",
    "            # shift the start time\n",
    "            current_start = row['start_time']\n",
    "            shifted_start = current_start + timedelta(hours=timeShift)\n",
    "            tasks.loc[x, 'start_time'] = shifted_start\n",
    "            \n",
    "            # shift the end time\n",
    "            current_end = row['end_time']\n",
    "            shifted_end = current_end + timedelta(hours=timeShift)\n",
    "            tasks.loc[x, 'end_time'] = shifted_end\n",
    "            \n",
    "    return tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Increase Duration\n",
    "This will increase the duration of the target task for each process and alter the timings of any subsequent tasks\n",
    "When iterating over tasks there are four potential conditions:\n",
    "1. We haven't found the target task in the tasks of a process - do nothing.\n",
    "2. We have found the target task so just increase the end time\n",
    "3. We have found a task the follows the target task, increase the start time and end time by the timedelta\n",
    "\n",
    "This logic treats repeat target tasks just like any other task that follows the first target, it only delays the first encounter with \n",
    "the target task. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def increaseDuration(tasks, target_attribute, target_value, target_task, timeShift):\n",
    "\n",
    "    # Logic requires we sort by process_id and start_date\n",
    "    tasks = tasks.sort_values(['process_id', 'start_time'])\n",
    "    tasks = tasks.reset_index(drop=True)\n",
    "    process_being_modified = -1\n",
    "    target_task_counter = 0\n",
    "    \n",
    "    # iterate through the dataframe using the index value\n",
    "    for x in tasks.index:\n",
    "        row = tasks.loc[x]\n",
    "        task_attribute = row[target_attribute]\n",
    "        row_task = row['task']\n",
    "        current_process = row['process_id']\n",
    "        processing_target_task = False\n",
    "        \n",
    "        # reset the target task counter when we come across a new process\n",
    "        if current_process !=  process_being_modified:\n",
    "            target_task_counter = 0\n",
    "\n",
    "        # Have we found a task of the target type with a target attribute matching the target value?\n",
    "        if row_task == target_task and task_attribute == target_value:\n",
    "            process_being_modified = current_process\n",
    "            target_task_counter = target_task_counter + 1\n",
    "            \n",
    "            # If this is the first target task in this process then\n",
    "            # just increase the duration by increasing the end_time\n",
    "            if target_task_counter == 1: \n",
    "                current_end = row['end_time']\n",
    "                shifted_end = current_end + timedelta(hours=timeShift)\n",
    "                tasks.loc[x, 'end_time'] = shifted_end\n",
    "            else:\n",
    "                current_start = row['start_time']\n",
    "                shifted_start = current_start + timedelta(hours=timeShift)\n",
    "                tasks.loc[x, 'start_time'] = shifted_start\n",
    "            \n",
    "                current_end = row['end_time']\n",
    "                shifted_end = current_end + timedelta(hours=timeShift)\n",
    "                tasks.loc[x, 'end_time'] = shifted_end\n",
    "                \n",
    "        # If we are processing ANY subsequent task that follows the target task \n",
    "        # this means shifting the start time and the end time.\n",
    "        elif target_task_counter > 0:\n",
    "                current_start = row['start_time']\n",
    "                shifted_start = current_start + timedelta(hours=timeShift)\n",
    "                tasks.loc[x, 'start_time'] = shifted_start\n",
    "            \n",
    "                current_end = row['end_time']\n",
    "                shifted_end = current_end + timedelta(hours=timeShift)\n",
    "                tasks.loc[x, 'end_time'] = shifted_end\n",
    "            \n",
    "    return tasks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Initialise Data Generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Task Duration Config\n",
    "For each task type that could be generated we need an average duration and a maximum duration."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = [['New Client Onboarding Request', 0.5,1.5], \n",
    "        ['Review Documents', 0.25,  2.5], \n",
    "        ['Automated Scoreboarding', 0.1, 0.15],\n",
    "        ['Manual Scoreboarding', 1.0, 3.0],\n",
    "        ['Update Backend Systems', 0.25, 0.5],\n",
    "        ['Notification Review Request Completed', 0.1, 0.15]\n",
    "       ]\n",
    "\n",
    "task_duration_df = pd.DataFrame(data, columns=['Task', 'Avg', 'Max'])\n",
    "task_duration_df.set_index('Task', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task_duration_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reset Counters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_date_time = datetime(2017, 11, 28, 18, 00, 00)\n",
    "instance_time_offset = 24\n",
    "instance_counter = 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Happy Path Instances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "qty = 900\n",
    "happy_path = [\"New Client Onboarding Request\", \n",
    "               \"Review Documents\", \n",
    "               \"Automated Scoreboarding\",\n",
    "               \"Update Backend Systems\", \n",
    "               \"Notification Review Request Completed\"]\n",
    "\n",
    "happy_path_task_list = []\n",
    "happy_path_task_list = generate_process_instances(happy_path, qty)\n",
    "happy_path_task_list_df = pd.DataFrame(happy_path_task_list)\n",
    "\n",
    "# Increment the start time by 24 hour\n",
    "start_date_time = start_date_time + timedelta(hours=24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "happy_path_task_list_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Instances Requiring Manual Scoreboarding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "qty = 80\n",
    "manual_path = [\"New Client Onboarding Request\", \n",
    "               \"Review Documents\", \n",
    "               \"Automated Scoreboarding\",\n",
    "               \"Manual Scoreboarding\",\n",
    "               \"Update Backend Systems\", \n",
    "               \"Notification Review Request Completed\"]\n",
    "\n",
    "manual_path_task_list = []\n",
    "manual_path_task_list = generate_process_instances(manual_path, qty)\n",
    "manual_path_task_list_df = pd.DataFrame(manual_path_task_list)\n",
    "\n",
    "# Increment the start time by 24 hour\n",
    "start_date_time = start_date_time + timedelta(hours=24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "manual_path_task_list_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Instance that loop\n",
    "Create processes that loop back to Review Docs from Manual Scoreboarding."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qty = 20\n",
    "loop_path = [\"New Client Onboarding Request\", \n",
    "               \"Review Documents\", \n",
    "               \"Automated Scoreboarding\",\n",
    "               \"Manual Scoreboarding\",\n",
    "               \"Review Documents\",\n",
    "               \"Update Backend Systems\", \n",
    "               \"Notification Review Request Completed\"]\n",
    "\n",
    "loop_path_task_list = []\n",
    "loop_path_task_list = generate_process_instances(loop_path, qty)\n",
    "loop_path_task_list_df = pd.DataFrame(loop_path_task_list)\n",
    "\n",
    "# Increment the start time by 24 hour\n",
    "start_date_time = start_date_time + timedelta(hours=24)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Can only concat two dataframes at a time\n",
    "df = pd.concat([happy_path_task_list_df,manual_path_task_list_df], axis=0)\n",
    "df = pd.concat([df,loop_path_task_list_df], axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns = ['process_id', 'task', 'start_time', 'end_time']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Confirm how many processes\n",
    "len(df[\"process_id\"].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Task Level Business Data : User"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Add a column for User\n",
    "df[\"user\"] = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def setRandomUser(row):\n",
    "    match row[\"task\"]:\n",
    "        case \"Review Documents\":\n",
    "            return random.choice(['Rod','Jane','Freddy'])\n",
    "        case \"New Client Onboarding Request\":\n",
    "            return random.choice(['Clive','Francis','Nick','Seb','Tom'])\n",
    "        case \"Manual Scoreboarding\":\n",
    "            return random.choice(['Sharon','Susan', 'Sam'])\n",
    "        case \"Update Backend Systems\":\n",
    "            return \"RPA\"\n",
    "        case \"Automated Scoreboarding\":\n",
    "            return \"SYSTEM\"\n",
    "        case \"Notification Review Request Completed\":\n",
    "            return \"SYSTEM\"\n",
    "        case _:\n",
    "            return row[\"user\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"user\"] = df.apply(setRandomUser, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Task Level Business Data : UserGroup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add a column for UserGroup\n",
    "df[\"user_group\"] = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def setUserGroup(row):\n",
    "    match row[\"task\"]:\n",
    "        case \"Review Documents\":\n",
    "            return \"Operations\"\n",
    "        case \"New Client Onboarding Request\":\n",
    "            return \"Sales\" \n",
    "        case \"Manual Scoreboarding\":\n",
    "            return \"Risk\"\n",
    "        case \"Update Backend Systems\":\n",
    "            return \"SYSTEM\"\n",
    "        case \"Automated Scoreboarding\":\n",
    "            return \"SYSTEM\"\n",
    "        case \"Notification Review Request Completed\":\n",
    "            return \"SYSTEM\"\n",
    "        case _:\n",
    "            return \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"user_group\"] = df.apply(setUserGroup, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Process Instance Business Data : Industry\n",
    "Industy won't change during the process so all tasks for a given process ID must have the same value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"industry\"] = \"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "process_id_list = df[\"process_id\"].unique()\n",
    "\n",
    "for process_id in process_id_list:\n",
    "    ind = random.choice(['Federal','Finance','Healthcare','Insurance','Telecom'])\n",
    "\n",
    "    # Update all rows in the df where the process_id = process_id setting industry to the value of ind\n",
    "    df.loc[df[\"process_id\"].eq(process_id), \"industry\"] = ind\n",
    "    \n",
    "                          \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add Process Instance Business Data : Service Charge\n",
    "Service charge will be a random choice based on industry."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"service_charge\"] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getServiceChargeByIndustry(industry):\n",
    "    match industry:\n",
    "        case \"Federal\":\n",
    "            return random.choice([3000, 6000, 8000])\n",
    "        case \"Finance\":\n",
    "            return random.choice([10000, 12000, 20000])\n",
    "        case \"Healthcare\":\n",
    "            return random.choice([15000, 20000, 25000])\n",
    "        case \"Insurance\":\n",
    "            return 45000\n",
    "        case \"Telecom\":\n",
    "            return 49000\n",
    "        case _:\n",
    "            return 64000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_process = -1\n",
    "service_charge = 0\n",
    "\n",
    "process_id_list = df[\"process_id\"].unique()\n",
    "\n",
    "for process_id in process_id_list:\n",
    "        # get the tasks for this process instance, use copy() to make it clear to the interpreter we know\n",
    "        # this is a copy to supress any warnings about updating copies\n",
    "        process_instance_tasks = df.loc[df.process_id == process_id].copy()\n",
    "        # Get the fir row out of the task list and get the industry value\n",
    "        industry = process_instance_tasks.iloc[0]['industry']\n",
    "        \n",
    "        # call function to get a semi-random service charge for the industry\n",
    "        service_charge = getServiceChargeByIndustry(industry)\n",
    "        \n",
    "        # set the service charge in every row for this process instance\n",
    "        df.loc[df.process_id == process_id, 'service_charge'] = service_charge\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(50)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Stories\n",
    "Make a copy of the dataframe so we can restart here if required."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "story_df = df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Story : 1 - Rod is Too Busy\n",
    "Rod is always very busy doing other work, so he may not be able to start right away.\n",
    "Lets take a look at two `Review Documents` tasks that have been done by Rod. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filter = (story_df['task'] == 'Review Documents') & (story_df['user'] == 'Rod')\n",
    "story_df[filter].head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Delay the start time of Rod's `Review Documents` tasks by 1 hour"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# If user is Rod and activity is `Review Documents` shift the start_time by 1 hour\n",
    "# \n",
    "story_df = delayStartTime(story_df, 'user','Rod', 'Review Documents', 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets see the result of this change:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filter = (story_df['task'] == 'Review Documents') & (story_df['user'] == 'Rod')\n",
    "story_df[filter].head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Story : 2 - Complex Doc Review\n",
    "Increase the time taken for doc review by 2hrs when the industry is federal. \n",
    "The rationale here is that the documentation requirements are greater."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets look at some `Review Documents` where the industry is `Federal`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filter = (story_df['task'] == 'Review Documents') & (story_df['industry'] == 'Federal')\n",
    "story_df[filter].head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "story_df[story_df['process_id'] == 4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "story_df = increaseDuration(story_df, 'industry','Federal', 'Review Documents', 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "story_df[story_df['process_id'] == 4]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export Finished Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "story_df.to_csv('pm_tasks_1k.csv', index=False, date_format='%d-%m-%Y %H:%M:%S')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Just some cells for inspecting the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}